behaviors:
  MoveToGoal:
    trainer_type: ppo
    hyperparameters:
      batch_size: 128
      buffer_size: 2048
      beta: 5.0e-3
    network_settings:
      hidden_units: 256
      num_layers: 2
      normalize: false
    max_steps: 3e5
    time_horizon: 128
    summary_freq: 20000
{
    "name": "root",
    "gauges": {
        "MoveToGoal.Policy.Entropy.mean": {
            "value": 3.0451228618621826,
            "min": 3.0451228618621826,
            "max": 3.1756439208984375,
            "count": 2
        },
        "MoveToGoal.Policy.Entropy.sum": {
            "value": 152097.796875,
            "min": 152097.796875,
            "max": 158960.03125,
            "count": 2
        },
        "MoveToGoal.Step.mean": {
            "value": 99985.0,
            "min": 49992.0,
            "max": 99985.0,
            "count": 2
        },
        "MoveToGoal.Step.sum": {
            "value": 99985.0,
            "min": 49992.0,
            "max": 99985.0,
            "count": 2
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": -1.2707247734069824,
            "min": -4.11003303527832,
            "max": -1.2707247734069824,
            "count": 2
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": -2524.93017578125,
            "min": -4225.11376953125,
            "max": -2524.93017578125,
            "count": 2
        },
        "MoveToGoal.Environment.EpisodeLength.mean": {
            "value": 28.246783625730995,
            "min": 28.246783625730995,
            "max": 144.32558139534885,
            "count": 2
        },
        "MoveToGoal.Environment.EpisodeLength.sum": {
            "value": 48302.0,
            "min": 48302.0,
            "max": 49648.0,
            "count": 2
        },
        "MoveToGoal.Environment.CumulativeReward.mean": {
            "value": -0.4679107999264531,
            "min": -6.8203473493976645,
            "max": -0.4679107999264531,
            "count": 2
        },
        "MoveToGoal.Environment.CumulativeReward.sum": {
            "value": -799.6595570743084,
            "min": -2346.1994881927967,
            "max": -799.6595570743084,
            "count": 2
        },
        "MoveToGoal.Policy.ExtrinsicReward.mean": {
            "value": -0.4679107999264531,
            "min": -6.8203473493976645,
            "max": -0.4679107999264531,
            "count": 2
        },
        "MoveToGoal.Policy.ExtrinsicReward.sum": {
            "value": -799.6595570743084,
            "min": -2346.1994881927967,
            "max": -799.6595570743084,
            "count": 2
        },
        "MoveToGoal.Losses.PolicyLoss.mean": {
            "value": 0.024324233562486676,
            "min": 0.02253969418021977,
            "max": 0.024324233562486676,
            "count": 2
        },
        "MoveToGoal.Losses.PolicyLoss.sum": {
            "value": 0.12162116781243337,
            "min": 0.09015877672087907,
            "max": 0.12162116781243337,
            "count": 2
        },
        "MoveToGoal.Losses.ValueLoss.mean": {
            "value": 0.801341440876325,
            "min": 0.801341440876325,
            "max": 1.2142326171199482,
            "count": 2
        },
        "MoveToGoal.Losses.ValueLoss.sum": {
            "value": 4.006707204381625,
            "min": 4.006707204381625,
            "max": 4.856930468479793,
            "count": 2
        },
        "MoveToGoal.Policy.LearningRate.mean": {
            "value": 0.00025690009436664,
            "min": 0.00025690009436664,
            "max": 0.00028461285512904993,
            "count": 2
        },
        "MoveToGoal.Policy.LearningRate.sum": {
            "value": 0.0012845004718332,
            "min": 0.0011384514205161997,
            "max": 0.0012845004718332,
            "count": 2
        },
        "MoveToGoal.Policy.Epsilon.mean": {
            "value": 0.18563336,
            "min": 0.18563336,
            "max": 0.19487095000000004,
            "count": 2
        },
        "MoveToGoal.Policy.Epsilon.sum": {
            "value": 0.9281668,
            "min": 0.7794838000000002,
            "max": 0.9281668,
            "count": 2
        },
        "MoveToGoal.Policy.Beta.mean": {
            "value": 0.004283104663999999,
            "min": 0.004283104663999999,
            "max": 0.004744060404999999,
            "count": 2
        },
        "MoveToGoal.Policy.Beta.sum": {
            "value": 0.021415523319999998,
            "min": 0.018976241619999997,
            "max": 0.021415523319999998,
            "count": 2
        },
        "MoveToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        },
        "MoveToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1650937768",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\jeffe\\Documents\\Jamie's Work\\Unity Projects\\Learning-bots\\venv\\Scripts\\mlagents-learn --run-id simpleMoveToGoal --force",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cpu",
        "numpy_version": "1.21.6",
        "end_time_seconds": "1650938939"
    },
    "total": 1170.689572,
    "count": 1,
    "self": 0.021223700000064127,
    "children": {
        "run_training.setup": {
            "total": 0.6418137000000002,
            "count": 1,
            "self": 0.6418137000000002
        },
        "TrainerController.start_learning": {
            "total": 1170.0265345999999,
            "count": 1,
            "self": 2.785316300004297,
            "children": {
                "TrainerController._reset_env": {
                    "total": 52.4639487,
                    "count": 1,
                    "self": 52.4639487
                },
                "TrainerController.advance": {
                    "total": 1114.7662337999955,
                    "count": 112783,
                    "self": 3.0617040999775327,
                    "children": {
                        "env_step": {
                            "total": 1060.5058459000088,
                            "count": 112783,
                            "self": 852.152618700018,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 206.53505189999964,
                                    "count": 112783,
                                    "self": 8.038318900033175,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 198.49673299996647,
                                            "count": 110191,
                                            "self": 39.49313089996656,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 159.0036020999999,
                                                    "count": 110191,
                                                    "self": 159.0036020999999
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.8181752999911254,
                                    "count": 112782,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1101.2226807000097,
                                            "count": 112782,
                                            "is_parallel": true,
                                            "self": 405.05901000002143,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.03687049999999914,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.011452900000001875,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.025417599999997265,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.025417599999997265
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 696.1268001999883,
                                                    "count": 112782,
                                                    "is_parallel": true,
                                                    "self": 14.155634799956488,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 10.995571300015627,
                                                            "count": 112782,
                                                            "is_parallel": true,
                                                            "self": 10.995571300015627
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 625.6829463000134,
                                                            "count": 112782,
                                                            "is_parallel": true,
                                                            "self": 625.6829463000134
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 45.2926478000028,
                                                            "count": 112782,
                                                            "is_parallel": true,
                                                            "self": 28.573655500030185,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 16.718992299972612,
                                                                    "count": 225564,
                                                                    "is_parallel": true,
                                                                    "self": 16.718992299972612
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 51.198683800009064,
                            "count": 112782,
                            "self": 3.5269579999959646,
                            "children": {
                                "process_trajectory": {
                                    "total": 14.461663600012947,
                                    "count": 112782,
                                    "self": 14.461663600012947
                                },
                                "_update_policy": {
                                    "total": 33.21006220000015,
                                    "count": 10,
                                    "self": 15.757440400000036,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 17.452621800000117,
                                            "count": 300,
                                            "self": 17.452621800000117
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.2100000049031223e-05,
                    "count": 1,
                    "self": 1.2100000049031223e-05
                },
                "TrainerController._save_models": {
                    "total": 0.011023700000123426,
                    "count": 1,
                    "self": 6.510000002890592e-05,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.01095860000009452,
                            "count": 1,
                            "self": 0.01095860000009452
                        }
                    }
                }
            }
        }
    }
}